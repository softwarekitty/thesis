\subsection{Clustering implementation}

\subsubsection{Selecting regexes to include}
Regexes appearing in only one project were not included in the final behavioral analysis, because these regexes have already appealed to more than one project maintainer, and so are more likely to be of interest when determining common behaviors, which aligns with the goal of this study.  So of the 13,597 regexes of the corpus, 10,015 (74\%) regexes that were not found in multiple projects were not included.
An additional 711 (5\%) regexes were excluded that contain features not supported by Rex.  The remaining \textbf{2,871} (21\%) regexes were used in the similarity analysis technique described here.

The impact is that 923 (53\%) projects were excluded from the data set for the similarity analysis.  The remaining \textbf{730} (47\%) projects touched by some cluster remained relevant to the analysis. Omitted features are indicated in Table~\ref{table:featuresInTools} for Rex.  Further details about similarity matrix creation are available in Appendix~\ref{app:similarityMatrixCreation}.

\subsubsection{Markov clustering details}
The Markov Clustering Algorithm (MCL) is based on the principal that when taking a random walk within a graph, a random walker is more likely to stay within a cluster than to cross to another cluster~\cities{mclManual}.  A graph can be represented as a matrix of edge weights (the similarity matrix).  One step of a random walk can be simulated by multiplying this matrix by itself (i.e., the matrix after one step has cells $c_{i,j}$ containing the sum of multiplying column $i$ of $M$ with row $j$ of $M$.).  This is known as \emph{expansion}~\cities{mclManual}.  With MCL, the natural tendency of clusters to be emphasized using random walks is exacerbated by raising each matrix element to a power and then re-normalizing the matrix (so that random walks may continue).  This is known as \emph{inflation}~\cities{mclManual}.  Inflation effectively lowers smaller numbers more than large ones.  Edges between nodes in a cluster tend to remain intact (they were not lowered so much during the random walk) while all other edges are effectively pruned.  The algorithm works by alternating between $n$ expansion steps followed by inflation to the power $i$.  These steps are repeated until the matrix converges to a fixed point~\cities{mclManual}.  More detail about how MCL was tuned are available in Appendix~\ref{app:mclTuning}.
