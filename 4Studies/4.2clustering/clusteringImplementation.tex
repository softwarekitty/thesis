\subsection{Clustering implementation}

\subsubsection{Selecting regexes to include}
Earlier runs of the study determining behavioral similarity attempted to include all regexes - only to find that because only the clusters representing the most projects could be included in further analysis, regexes belonging to only one project had little affect on the results. In light of this and also due to the computationally intensive nature of building the similarity matrix, regexes appearing in only one project were not included in the final behavioral analysis.  So of the 13,597 regexes of the corpus, 10,015 (74\%) regexes that were not found in multiple projects were not included.
An additional 711 (5\%) regexes were excluded that contain features not supported by Rex.  The remaining \textbf{2,871} (21\%) regexes were used in the similarity analysis technique described here.

The impact is that 923 (53\%) projects were excluded from the data set for the similarity analysis.  The remaining \textbf{730} (47\%) projects touched by some cluster remained relevant to the analysis. Omitted features are indicated in Table~\ref{table:featuresInTools} for Rex.

\subsubsection{Similarity matrix creation details}
A free trial of Windows 7 was run within VMware on a macbook pro.  The Rex~\cities{rex} executable\footurl{http://research.microsoft.com/en-us/downloads/7f1d87be-f6d9-495d-a699-f12599cea030/} requires .Net 4.5, and the similarity matrix creating program was written in C\# using visual studio 2013.  First the patterns for 3,582 Python regexes appearing in multiple projects were used to try and generate strings using Rex, which rejected 711 patterns.  For the remaining 2,871 patterns that Rex could generate strings for, the test strings were stored in a distinct file for each regex, and delimited by a large random string (Rex often needs to generate muti-line test strings).

The filtered corpus of Rex-compatible regexes was written to a file to increase loading speed in the next step.  For each regex in the filtered corpus, the test strings stored for that regex were loaded and all other regexes attempted to match those strings.  Although regular expression engines usually perform a match quickly, an occasional pathological combination of regex and test string would cause the entire program to stall.  The Parallel.For(...) functionality of C\# was used to allow work to continue, but eventually the program had to be stopped using an interrupt.  This caused incomplete rows of data which needed to be pruned by a separate program and re-calculated.  All rows were verified in a final step before exporting the similarity matrix.

\subsubsection{Markov clustering details}
The Markov Clustering Algorithm (mcl) is based on the principal that when taking a random walk within a graph, a random walker is more likely to stay within a cluster than to cross to another cluster~\cities{mclManual}.  A graph can be represented as a matrix of edge weights (the similarity matrix).  One step of a random walk can be simulated by multiplying this matrix by itself (i.e., the matrix after one step has cells $c_{i,j}$ containing the sum of multiplying column $i$ of $M$ with row $j$ of $M$.).  This is known as \emph{expansion}~\cities{mclManual}.  With mcl, the natural tendency of clusters to be emphasized using random walks is exacerbated by raising each matrix element to a power and then re-normalizing the matrix (so that random walks may continue).  This is known as \emph{inflation}~\cities{mclManual}.  Inflation effectively lowers smaller numbers more than large ones.  Edges between nodes in a cluster tend to remain intact (they were not lowered so much during the random walk) while all other edges are effectively pruned.  The algorithm works by alternating between $n$ expansion steps followed by inflation to the power $i$.  These steps are repeated until the matrix converges to a fixed point~\cities{mclManual}.

The mcl tool takes many arguments, with the main value, $i$, controlling inflation.  A larger value of $i$ will produce more, smaller clusters, and visa versa.  A cutoff value $p$ below which edges are treated as zero, is also provided.  A third value $k$ can be used to customize the number of neighbor nodes to track per computation~\cities{mclManual}.  The default values for these three are 2, 0.75 and 4 respectively.  Extensive experimentation comparing the contents of clusters using various values for $i$, $p$ and $k$ led to the choice of $i=1.8$, $p=0.75$ and $k=83$.  Under the advisement of the mcl manual, the directional edges produced by the similarity determining technique were averaged to form a symmetric edge weight matrix before clustering~\cities{mclManual}.
