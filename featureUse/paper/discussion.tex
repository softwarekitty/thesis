\section{Discussion}
\label{sec:discussion}

In this section, we discuss the implications of these empirical findings
%on tool designers and users of regex tools
 and opportunities for future work.

\subsection{Implications For Tool Designers}
The results have  implications for regex tool designers. % who want to effectively support developers who use regular expressions.

%\subsubsection{All Character Classes Are Common}
%The same character class can be expressed in different ways, for example \verb!`[0-9]'! is equivalent to \verb!`\d'!.  Our results indicate that both approaches are widely used (Table~\ref{tab:cccvsdefault}), so tool builders should continue to support both approaches.


\subsubsection{Finding Specific Content}
Two categorical clusters, \emph{Specific Characters Must Match} (Section~\ref{cluster:single}) and \emph{Two or More Characters in Sequence} (Section~\ref{cluster:multiple}), deal with identifying the presence of specific character(s).
While multiple character matching subsumes single character matching, the overarching theme is that these regexes are looking to validate strings based on the presence of very specific content, as would be done for many common activities listed in Table~\ref{tab:regexactivities}, such as, ``Locating content within a file or files."
%(This is in contract to \emph{capturing} specific content, as \emph{finding} deals with string validation and \emph{capturing} deals with string extraction.)
%As indicated by the clusters of specific character matches in Section~\ref{cluster:single}, finding specific content is important.
%Delimiters that separate items on one line like \verb!`\t'! are also quite common.
%Although survey participants indicated an average frequency of 1.7 (very rarely or never) for ``checking for a single character," we found that 17 of the top 100 clusters revolved around the presence of a single character.
%The commonality of regexes related to finding content is consistent with the top ranked activity for developers, ``Locating content within a file or files."
%and usually this content is located using some small set of characters that the user knows will flag that content.
More study is needed into what content is most frequently searched for, but from our cluster analysis we found that version numbers, twitter or user handles, hex values, decimal numbers, capitalized words, and particular combinations of whitespace, slashes and other delimiters were discernible targets.

%Looking closely at the \emph{Specific Character Must Match} cluster, some of the characters being searched for were \verb!\n!, \verb!-! and \verb!.!, which are all common delimiters in different scenarios. This indicates the need for regex tools to facilitate easy file parsing, or for tools to include built-in support for specific, common types of parsing.


\subsubsection{Capturing Specific Content Near A Delimiter}
The survey results from Section~\ref{rq1:survey} indicate that capturing parts of strings is among the most frequent activities for which developers use regexes.
From a feature perspective, the capture group (CG) is the most frequently used in terms of patterns (Table~\ref{table:featureStats}).  This feature has two functions: 1) logical grouping as would be expected by parenthesis, and 2) retrieval of information in one logical grouping.  As mentioned in Section~\ref{rq4:results}, capturing content was a primary goal evident in several cluster categories.  The fourth-largest category is based entirely on capturing the content between brackets or parentheses (Section~\ref{cluster:contentparens}).

%Combined with the cluster on \emph{Code Search and Variable Capturing} (Section~\ref{cluster:search}), this emphasizes the need for regex tools to  facilitate easy file parsing, or for a tool to include built-in support for specific, common types of parsing.


Many uses of CG also use the ANY and KLE features, eg. \verb!(.*){(.*)}(.*)! and \verb!\\s*([^: ]*)\\s*:(.*)!.  This type of usage frequently revolves around an important delimiter character such as \verb!:! or \verb!\!.  This use case is well supported by existing tools for ASCII characters, but future tools should consider the centrality of this use case and its implications for non-English users of regex tools.  For example, Unicode characters like `U+060D' the Arabic Date Separator, or `U+1806' the Mongolian Todo Soft Hyphen may be used to locate segments of text that a user would want to capture.

%, such as finding a twitter handle (i.e., \verb!@[a-z]+!) or a version number, (i.e., \verb!v[0-9]+.*!).
%and then capture specific content, such as the actual twitter handle or the actual version number, but may not know how to do that capture groups and may rely on string parsing instead.

%\todoMid{The main difference between the Specific Character Must Match group and the multiple characters must match is that the first can subsume the second.  I think it's important to defend this and expose that we understand that our simplification of clusters to their shortest representative combined with the behavioral clustering technique will drastically over-emphasize similarities revolving around single characters, so instead of listing this as a major group, or a major finding, we may need to admit that it is an emphasis that our technique introduces artificially.  I think that in practice, the patterns being searched for usually revolve around more than just a single character, although maybe not a lot more than that.  I think it is more telling that despite our technique's tendency to over-cluster things around a single character, there was still an entire category that required two or more characters, and so those specific pairs or triples or whatever in that cluster are extremely key character combinations.  Let's see a few of those that seem to make sense: }
%\verb! {2,}!
%\todoMid{ :two or more spaces, }
%\verb!@[a-z]+!
%\todoMid{ :a lowercase twitter handle or similar,}
% \verb!\\$[()]!
% \todoMid{ :a dollar followed by either paren, }
% \verb!v[0-9]+.*!
% \todoMid{ :the letter `v' followed by some numbers, perhaps a version number.  }

\subsubsection{Counting Lines}
Text files containing one unit of information per line are common in a wide variety of applications (for example .log and .csv files).  Out of the 13,597 patterns in the corpus, 3,410 (25\%) contained ANY followed by KLE  (i.e., \verb!`.*'!), often at the end of the pattern.
One reasonable explanation for this tendency to put \verb!`.*'! at the end of a pattern is that users want to disregard all matches after the first match on a single line in order to count how many distinct lines the match occurs on.  Survey participants indicated an average frequency of ``Counting lines that match a pattern" and ``Counting substrings that match a pattern" at 3.2 or rarely/occasionally. It may be valuable for tool builders to include support for common activities such as line counting.



%\todoMid{In a completely unrelated train of thought, I have been considering how regexes are one major way, and perhaps the only practical way in the world of computer science to handle the invisible characters like ASCII 0-32.  That's 33 characters like `backspace' and `end of medium' and 'vertical tab' that can appear in text and cause problems.  I've heard them called `Gremlins'.  So what do people do?  They write regexes to clean those out.}



\subsection{Opportunities For Future Work}

There are many opportunities for future work. %\todoLast{Hey Kids! Need a thesis topic? Here's a bunch! Promote this awesome section earlier}




\subsubsection{Refactoring Regexes}
The survey showed that users want readability and find the lack of readable regexes to be a major pain point.
This provides an opportunity to introduce refactoring transformations to enhance readability or comprehension.
As one opportunity, certain character classes are logically equivalent and can be expressed differently, for example, \verb!\d! $\equiv$ \verb![0123456789]! $\equiv$ \verb![0-9]!. While \verb!\d! is more succinct, \verb![0-9]! may be easier to read, so a refactoring for \emph{default to custom character classes} could be introduced.
Human studies are needed to evaluate the readability and comprehension of various regex features in order to define and support appropriate regex refactorings.

Another avenue of refactoring could be for performance. Various implementations of regex libraries may perform more efficiently with some features than others. An evaluation of regex feature implementation speeds would facilitate semantic transformations based on performance, similar to performance refactorings for LabVIEW~\cite{chambers2013smell, chambers2015impact}.


Additionally, some developers may  \emph{find} specific content with a regex  and then subsequently \emph{capture} it with string parsing, which may be more error prone than using a capture group and indicates a missed opportunity to use the full extent of regex libraries. Future work will explore source code to identify the frequency of such occurrences and design refactorings to better utilize regex library features.

%Other similar refactoring techniques may become evident with a more thorough search.  A tool that preserved the exact behavior of a regex but optimized for readability could be incorporated into an IDE and relieve some developer pain.  More research is needed into why certain character classes are considered more readable, as has been done for other refactoring work (e.g.,~\cite{StoleeTSE2013}).
%Similarly, there are several principals that can be followed to enhance the performance of a regex.  Using non-capture groups whenever possible, avoiding backtracking, etc.  In theory it seems possible to build a compiler that could compose a regex with identical behavior but with better readability and performance.

\vspace{-2pt}
\subsubsection{Migration  Support for Developers}
Within standard programming languages, regular expressions libraries are very common, yet there are subtle  differences between language libraries in the supported features. For example, Java supports possessive quantifiers like \verb! `ab*+c'! (here the `+' is modifying the `*' to make it possessive) whereas Python does not. Differences among programming language implementations was identified as a pain point for using regular expressions by 17\% of the survey participants. This provides a future opportunity for tools that translate between regex utilizations in various languages.

\vspace{-2pt}
\subsubsection{Similarity Beyond String Matching}
There are various ways to compute similarity between regexes, each with different tradeoffs.
While the similarity analysis we employ over-approximates similarity when compared to containment analysis, it may under-approximate similarity in another sense.
%We define behavioral similarity based on strings matched by pairs of regular expressions. However, t
For example, two regexes that have dissimilar matching behavior could be very similar in purpose and in the eyes of the developer. For example, \verb!commit:\[(\d+)\] - (.*)! and \verb!push:\[(\d+)\] - (.*)! could both be used to  capture the id and command from a versioning system, but match very different sets of strings. Future work would apply abstractions to the regex strings, such as removing or relaxing literals, prior to similarity analysis to capture and cluster such similarities.

From another perspective, our regex similarity measure, and even containment analysis, could treat behaviorally identical regexes as the same, when  their usage in practice is completely different. For example, in Table~\ref{table:exampleCluster}, the regexes \verb!`:+'! and \verb!`(:+)'! are behaviorally identical in that they match the same strings, except the latter uses a capture group. In practice, these may be used very differently, where the former may be used for validation and the latter for extraction. This usage difference could be observed by code  analysis, and is left for future work.

\vspace{-2pt}
\subsubsection{Automated Regex Repair}
Regular expression errors are common and have produced thousands of bug reports~\cite{Spishak:2012:TSR:2318202.2318207}. This provides an opportunity to introduce automated repair techniques for regular expressions.
Recent approaches to automated program repair rely on mutation operators to make small changes to source code and then re-run the test suite (e.g., ~\cite{cacm10, genprog-tse-journal}). In regular expressions, it is likely that the broken regex is close, semantically, to the desired regex. Syntax changes through mutation operators could lead to big changes in behavior, so we hypothesize that using the semantic clusters identified in Section~\ref{rq4:results} to identify potential repair candidates could efficiently and effectively converge on a repair candidate.

\subsubsection{Developer Awareness of Best Practices}
One category of clusters, \emph{Content of Brackets and Parenthesis}, parses the contents of angle brackets, which may indicate developers are using regexes to parse HTML or XML.  As the contents of angle brackets are usually unconstrained, regexes are a poor replacement for XML or HTML parsers.  This may be a missed opportunity for the regex users to take advantage of more robust tools. More research is needed into how regex users discover best practices and how aware they are of how regexes should and should not be used.
%http://english.stackexchange.com/questions/50851/the-contents-are-or-the-contents-is

%\subsubsection{Support for Regexes Composition}
%According to our survey, over 60\% of developers find regexes to be difficult to compose. Additionally, developers frequently or very frequently write tests for their regexes. This provides an opportunity to instead





\subsubsection{Tool-Specific Regex Exploration}
In some environments, such as command line or text editor, regexes are used extensively by the surveyed developers (Section~\ref{rq1:survey}), but these regular expressions do not persist. Thus, using a repository analysis for feature usage only illustrates part of how regexes are used in practice. Exploring how the feature usage differs between environments would help inform tool developers about how to best support regex usage in context, and is left for future work.


% \subsubsection{A Modern WRD Character Class}
% \todoMid{update}
% One unexpected result of our clustering is that, behaviorally speaking, the negation of the word class NWRD was used in 208 projects, while the word class itself was used in only 114 projects. After inspecting several projects using the patterns found in this behavioral cluster, we concluded that most users are trying to sanitize arbitrary strings that must conform to a system character set requirement, such as requirements for filenames.  For example, a user might replace all NWRD matching characters with the `\_' to guarantee that an arbitrary string can be used as a filename.  We also considered the largest cluster using custom character classes (\verb?`[^ -~]'(122)?) and concluded that users are constructing a more permissive version of the NWRD character class, to allow more non-letter, non-digit characters than just the `\_' in their sanitized strings.  More research is needed to determine if a more modern WRD class could be useful, and if so, what characters set is preferred.


