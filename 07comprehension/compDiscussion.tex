\section{Discussion of comprehension results}
Three statistically significant refactorings $\overrightarrow{T4 T1}$, $\overrightarrow{D2 D3}$, and $\overrightarrow{L2 L3}$ were identified by the results presented in Table~\ref{table:testedEdgesTable}.  A detailed view of the results for these three refactorings is presented in Table~\ref{table:pairwiseRefactorings}.  The first refactoring, $\overrightarrow{T4 T1}$, makes sense because the octal syntax is far more exotic and difficult to understand than plain characters. Composition improves notably from 23\% for \cverb!([\0175\0173])! to 87\% for \cverb!([}{}])!.  This results seems likely to generalize, as there is nothing unusual about the regexes that might cause noise.

The second refactoring $\overrightarrow{D2 D3}$, reduces confusion caused by expanding the entire set of strings specified by the regex into an OR.  If the OR feature is understood, then the regexes in D3 are very straightforward, whereas the QST repetition may take a little thought.  This refactoring is not likely to scale, however, because a slightly more complicated regex like \cverb!a?b*(cd)?e?! would expand to the very long regex \cverb!ab*cde|b*cde|ab*e|b*e|ab*cd|b*cd|ab*|b*! which introduces the new challenge of visually parsing and remembering eight strings.

The third refactoring, $\overrightarrow{L2 L3}$ makes sense because the ADD feature is a very widely used feature, and getting rid of the extra character that may appear zero times makes the minimal-length string more apparent.  Matching scores only improved by 4\%-7\%, and most composing scores only improved by 3\%.  The exception is the composing score of \cverb!\..*! (80\%) vs the composing score of \cverb!\.+! (93\%) showing a 13\% improvement.  This may be partially due to the escaped


\subsection{Implications}
\subsection{Opportunities for future work}
\subsection{Threats to validity}

\todoMid{Discuss the backslash explosions and readability issues!}


\paragraph{Understandability}
We identified and utilized three new ways to measure understandability of regexes: deciding if certain strings match or not, composing strings that are supposed to match, and measuring the frequency of a regex type in a community.  There are many more ways to approach understandability, such as deciding what content is captured by a regex, identifying all the matched substrings in a block of text, deciding which regexes in a set are equivalent, finding the minimum modification to some text so that a given regex will match it, and many more.  One of the most straightforward ways to address understandability is to directly ask software professionals which from a list of equivalent regexes they prefer and why.  It may also be meaningful to provide some code that exists around a regex as context.  The example regexes we used were inspired by real regexes, but at least one side of the refactoring was contrived and we did not focus on any specific community (the 1544 projects we obtained regexes from were randomly obtained).  If understandability measurements used regexes sampled from the codebase of a specific community(most frequently observed regexes, most buggy regexes, regexes on the hottest execution paths, etc.), and measured the understanding of programming professionals working in that community, then the measurements and the refactorings they imply would be more likely to have a direct and certain positive impact.
In another study, we did a survey where software professionals indicated that understandability of regexes they find in source code is a major pain point.  In this study, our participants indicated that they read about twice as many regexes as they compose.  What is the impact on maintainers, developers and contributors to open-source projects of not being able to understand a regex that they find in the code they are working with?  Presumably this is a frustrating experience - how much does a confusing regex slow down a software professional?  What bugs or other negative factors can be attributed to or associated with regexes that are difficult to understand?  How often does this happen and in what settings?  Future work could tailor an in-depth exploration of the overall costs of confusing regexes and the potential benefits of refactoring or other treatments for confusing regexes.


But the range \verb![a-f]! is likely to be more understandable for most people than a range like \verb![:-`]!. By creating a more granular model of equivalence classes, and making sure to carefully evaluate alternative representations of the most frequently used specific patterns (like \verb!\\s*! and \verb!.+!), many more strong and useful refactorings could be identified.

Presently, we are not aware of coding standards for regular expressions, but this work suggests that enforcing standard representations for various regex constructs could ease comprehension.
